# Dataset ë° ì¶”ê°€ Data path:
https://github.com/V2LLAIN/Data_Science/tree/main/TermProject/Dataset

https://drive.google.com/file/d/1J0RKORgYZWjCIENYacyAsbPru-NjRRkd/view?usp=sharing
#
# ğŸ“• í•™ìŠµì§„í–‰í•˜ëŠ”ë°©ë²•:

### weight ì¡°ì • 
#### ìˆœì„œëŒ€ë¡œ MultinomialNB, SGDClassifier, LBBMClassifier, CatBoostClassifier
    python train.py --weights 0.1 0.2 0.3 0.4

### p6ê³¼ catboostclassifierì˜ learning_rate ì¡°ì •
    python train.py --p6_learning_rate 2e-4 --cat_learning_rate 2e-4

### VOCAB_SIZE, MAX_LEN ì¡°ì •
    python train.py --MAX_LEN 1024 --VOCAB_SIZE 31000

### JR Datasetìœ¼ë¡œ score ì¶œë ¥í•˜ëŠ”ë°©ë²•.  
(--test="ê²½ë¡œ" ì„¤ì •í•œ í›„)
(ì•„ë˜ì½”ë“œ train.pyì— ì¶”ê°€ë° ë³€ê²½)
    y_preds = ensemble.predict_proba(tf_test)[:, 1]
    sub = test.copy()
    sub['generated'] = y_preds > 0.5
    sub.to_csv(args.submission, index=False)
    sub['generated'] = y_preds > 0.5
    print(float(np.sum(test['generated'] == sub['generated'])) / len(test))




ì™€ ê°™ì€ ë°©ì‹ìœ¼ë¡œ train ë° submissioníŒŒì¼ ìƒì„±ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.

ğŸ“Œ ì¶”ê°€ì ìœ¼ë¡œ 
- íŒŒì¼ê²½ë¡œ(test, sub, org_train, train, submission)
- max_iter ë° learning_rate, metric
- max_depth, max_bin, loss
- VOCAB_SIZE, MAX_LEN, LOWERCASE
- weights, votingì¢…ë¥˜
ë˜í•œ terminalì—ì„œ í•™ìŠµ ì‹œ ì¡°ì •ê°€ëŠ¥.
##
ğŸ“Œ Additionally, adjustable during training in the terminal:
- File paths (test, sub, org_train, train, submission)
- max_iter, learning_rate, metric
- max_depth, max_bin, loss
- VOCAB_SIZE, MAX_LEN, LOWERCASE
- weights, types of voting
##
