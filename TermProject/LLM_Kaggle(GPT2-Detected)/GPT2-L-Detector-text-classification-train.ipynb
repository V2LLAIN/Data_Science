{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012455,
     "end_time": "2022-08-31T07:01:57.321119",
     "exception": false,
     "start_time": "2022-08-31T07:01:57.308664",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<img src=\"https://i.imgur.com/Y1CTNy9.jpeg\">\n",
    "\n",
    "# <b><span style='color:#F1A424'>|</span> DAIGT: <span style='color:#F1A424'>Text Classification</span><span style='color:#ABABAB'> [Train]</span></b> \n",
    "\n",
    "***\n",
    "\n",
    "Your goal in this competition is to differentiate essays written by students from essays written by AI, like ChatGPT for instance. The competition provides only student-generated data. Because of this, we will use the dataset I created which contains both 2421 student-generated essays as well as 2421 AI-generated essays, more than 4 times the original data.\n",
    "\n",
    "In this notebook you will learn how to train a `deberta-v3-base` model for text classification using PyTorch. Hope you enjoy it and find it useful.\n",
    "\n",
    "### <b><span style='color:#F1A424'>Table of Contents</span></b> <a class='anchor' id='top'></a>\n",
    "<div style=\" background-color:#3b3745; padding: 13px 13px; border-radius: 8px; color: white\">\n",
    "<li> <a href=\"#introduction\">Introduction</a></li>\n",
    "<li> <a href=\"#install_libraries\">Install libraries</a></li>\n",
    "<li><a href=\"#import_libraries\">Import Libraries</a></li>\n",
    "<li><a href=\"#configuration\">Configuration</a></li>\n",
    "<li><a href=\"#utils\">Utils</a></li>\n",
    "<li><a href=\"#load_data\">Load Data</a></li>\n",
    "<li><a href=\"#validation\">Validation</a></li>\n",
    "<li><a href=\"#dataset\">Tokenizer</a></li>\n",
    "<li><a href=\"#dataset\">Dataset</a></li>\n",
    "<li><a href=\"#model\">Model</a></li>\n",
    "<li><a href=\"#loss\">Loss Function</a></li>\n",
    "<li><a href=\"#functions\">Train and Validation Functions</a></li>\n",
    "<li><a href=\"#train_loop\">Train Loop</a></li>\n",
    "<li><a href=\"#train\">Train</a></li>\n",
    "</div>\n",
    "\n",
    "\n",
    "# <b><span style='color:#F1A424'>|</span> Introduction</b><a class='anchor' id='introduction'></a> [‚Üë](#top) \n",
    "\n",
    "***\n",
    "\n",
    "### <b><span style='color:#F1A424'>Useful References</span></b>\n",
    "\n",
    "- [DAIGT | Deberta Text Classification [Inference]](https://www.kaggle.com/alejopaullier/daigt-deberta-text-classification-train)\n",
    "- [Y.Nakama | FB3 / Deberta-v3-base baseline [train]](https://www.kaggle.com/code/yasufuminakama/fb3-deberta-v3-base-baseline-train)\n",
    "- [Y.Nakama | FB3 / Deberta-v3-base baseline [inference]](https://www.kaggle.com/code/yasufuminakama/fb3-deberta-v3-base-baseline-inference/notebook)\n",
    "- [Deberta v3 Hugging Face](https://huggingface.co/microsoft/deberta-v3-base)\n",
    "- [Deberta paper](https://arxiv.org/abs/2006.03654)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b><span style='color:#F1A424'>|</span> Import Libraries</b><a class='anchor' id='import_libraries'></a> [‚Üë](#top) \n",
    "\n",
    "***\n",
    "\n",
    "Import all the required libraries for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  kaggle.zip\n",
      "   creating: kaggle/\n",
      "  inflating: kaggle/.DS_Store        \n",
      "  inflating: __MACOSX/kaggle/._.DS_Store  \n",
      "   creating: kaggle/input/\n",
      "   creating: kaggle/working/\n",
      "  inflating: kaggle/input/.DS_Store  \n",
      "  inflating: __MACOSX/kaggle/input/._.DS_Store  \n",
      "  inflating: kaggle/input/submission.csv  \n",
      "  inflating: __MACOSX/kaggle/input/._submission.csv  \n",
      "   creating: kaggle/input/daigt-models/\n",
      "   creating: kaggle/input/daigt-external-dataset/\n",
      "   creating: kaggle/input/llm-detect-ai-generated-text/\n",
      "  inflating: kaggle/input/sample_submission.csv  \n",
      "  inflating: __MACOSX/kaggle/input/._sample_submission.csv  \n",
      "  inflating: kaggle/working/.DS_Store  \n",
      "  inflating: __MACOSX/kaggle/working/._.DS_Store  \n",
      "   creating: kaggle/working/output/\n",
      "  inflating: kaggle/input/daigt-models/.DS_Store  \n",
      "  inflating: __MACOSX/kaggle/input/daigt-models/._.DS_Store  \n",
      "   creating: kaggle/input/daigt-models/model_v2/\n",
      "  inflating: kaggle/input/daigt-external-dataset/daigt_external_dataset.csv  \n",
      "  inflating: __MACOSX/kaggle/input/daigt-external-dataset/._daigt_external_dataset.csv  \n",
      "  inflating: kaggle/input/llm-detect-ai-generated-text/.DS_Store  \n",
      "  inflating: __MACOSX/kaggle/input/llm-detect-ai-generated-text/._.DS_Store  \n",
      "  inflating: kaggle/input/llm-detect-ai-generated-text/train_prompts.csv  \n",
      "  inflating: __MACOSX/kaggle/input/llm-detect-ai-generated-text/._train_prompts.csv  \n",
      "  inflating: kaggle/input/llm-detect-ai-generated-text/test_essays.csv  \n",
      "  inflating: __MACOSX/kaggle/input/llm-detect-ai-generated-text/._test_essays.csv  \n",
      "  inflating: kaggle/input/llm-detect-ai-generated-text/train_essays.csv  \n",
      "  inflating: __MACOSX/kaggle/input/llm-detect-ai-generated-text/._train_essays.csv  \n",
      "  inflating: kaggle/input/llm-detect-ai-generated-text/sample_submission.csv  \n",
      "  inflating: __MACOSX/kaggle/input/llm-detect-ai-generated-text/._sample_submission.csv  \n",
      "  inflating: kaggle/working/output/.DS_Store  \n",
      "  inflating: __MACOSX/kaggle/working/output/._.DS_Store  \n",
      "   creating: kaggle/working/output/tokenizer/\n",
      "  inflating: kaggle/input/daigt-models/model_v2/.DS_Store  \n",
      "  inflating: __MACOSX/kaggle/input/daigt-models/model_v2/._.DS_Store  \n",
      "   creating: kaggle/input/daigt-models/model_v2/content/\n",
      "  inflating: kaggle/working/output/tokenizer/.DS_Store  \n",
      "  inflating: __MACOSX/kaggle/working/output/tokenizer/._.DS_Store  \n",
      "  inflating: kaggle/input/daigt-models/model_v2/content/.DS_Store  \n",
      "  inflating: __MACOSX/kaggle/input/daigt-models/model_v2/content/._.DS_Store  \n",
      "   creating: kaggle/input/daigt-models/model_v2/content/output/\n",
      "  inflating: kaggle/input/daigt-models/model_v2/content/output/.DS_Store  \n",
      "  inflating: __MACOSX/kaggle/input/daigt-models/model_v2/content/output/._.DS_Store  \n"
     ]
    }
   ],
   "source": [
    "!unzip kaggle.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current device is: cuda\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import copy\n",
    "import gc\n",
    "import itertools\n",
    "import joblib\n",
    "import json\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "import scipy as sp\n",
    "import string\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "import wandb\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# ======= OPTIONS =========\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Current device is: {device}\")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "!mkdir output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b><span style='color:#F1A424'>Tokenizers and transformers</span></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=true\n",
      "tokenizers.__version__: 0.14.1\n",
      "transformers.__version__: 4.34.1\n"
     ]
    }
   ],
   "source": [
    "import tokenizers\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
    "%env TOKENIZERS_PARALLELISM=true\n",
    "print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n",
    "print(f\"transformers.__version__: {transformers.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.006569,
     "end_time": "2022-08-31T07:01:57.395826",
     "exception": false,
     "start_time": "2022-08-31T07:01:57.389257",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <b><span style='color:#F1A424'>|</span> Configuration</b><a class='anchor' id='configuration'></a> [‚Üë](#top) \n",
    "\n",
    "***\n",
    "\n",
    "Central repository for this notebook's hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "papermill": {
     "duration": 0.015868,
     "end_time": "2022-08-31T07:01:57.417077",
     "exception": false,
     "start_time": "2022-08-31T07:01:57.401209",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class config:\n",
    "    APEX = True # Automatic Precision Enabled\n",
    "    BATCH_SCHEDULER = True\n",
    "    BATCH_SIZE_TRAIN = 32\n",
    "    BATCH_SIZE_VALID = 16\n",
    "    BETAS = (0.9, 0.999)\n",
    "    DEBUG = False\n",
    "    DECODER_LR = 2e-5\n",
    "    ENCODER_LR = 2e-5\n",
    "    EPOCHS = 5\n",
    "    EPS = 1e-6\n",
    "    FOLDS = 4\n",
    "    GRADIENT_ACCUMULATION_STEPS = 1\n",
    "    GRADIENT_CHECKPOINTING = True\n",
    "    MAX_GRAD_NORM=1000\n",
    "    MAX_LEN = 512\n",
    "    MIN_LR = 1e-6\n",
    "    MODEL = \"bettertextapp/gpt2-large-detector-de-v1\"\n",
    "    NUM_CYCLES = 0.5\n",
    "    NUM_WARMUP_STEPS = 0\n",
    "    NUM_WORKERS = multiprocessing.cpu_count()\n",
    "    PRINT_FREQ = 20\n",
    "    SCHEDULER = 'cosine' # ['linear', 'cosine']\n",
    "    SEED = 27\n",
    "    TRAIN = True\n",
    "    TRAIN_FOLDS = [0, 1, 2, 3]\n",
    "    WANDB = False\n",
    "    WEIGHT_DECAY = 0.01\n",
    "\n",
    "    \n",
    "class paths:\n",
    "    OUTPUT_DIR = \"./kaggle/working/output\"\n",
    "    EXTERNAL_DATA = \"./kaggle/input/daigt-external-dataset/daigt_external_dataset.csv\"\n",
    "    TRAIN_PROMPTS = \"./kaggle/input/llm-detect-ai-generated-text/train_prompts.csv\"\n",
    "    TRAIN_ESSAYS = \"./kaggle/input/llm-detect-ai-generated-text/train_essays.csv\"\n",
    "    TEST_ESSAYS = \"./kaggle/input/llm-detect-ai-generated-text/test_essays.csv\"\n",
    "    \n",
    "\n",
    "if config.DEBUG:\n",
    "    config.EPOCHS = 2\n",
    "    config.TRAIN_FOLDS = [0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.007998,
     "end_time": "2022-08-31T07:03:04.079768",
     "exception": false,
     "start_time": "2022-08-31T07:03:04.07177",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <b><span style='color:#F1A424'>|</span> Utils</b><a class='anchor' id='utils'></a> [‚Üë](#top) \n",
    "\n",
    "***\n",
    "\n",
    "Utility functions used throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "papermill": {
     "duration": 0.024132,
     "end_time": "2022-08-31T07:03:04.111108",
     "exception": false,
     "start_time": "2022-08-31T07:03:04.086976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_config_dict(config):\n",
    "    \"\"\"\n",
    "    Return the config, which is originally a class, as a Python dictionary.\n",
    "    \"\"\"\n",
    "    config_dict = dict((key, value) for key, value in config.__dict__.items() \n",
    "    if not callable(value) and not key.startswith('__'))\n",
    "    return config_dict\n",
    "\n",
    "\n",
    "def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_parameters = [\n",
    "        {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "         'lr': encoder_lr, 'weight_decay': weight_decay},\n",
    "        {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "         'lr': encoder_lr, 'weight_decay': 0.0},\n",
    "        {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n",
    "         'lr': decoder_lr, 'weight_decay': 0.0}\n",
    "    ]\n",
    "    return optimizer_parameters\n",
    "\n",
    "\n",
    "def get_logger(filename=paths.OUTPUT_DIR):\n",
    "    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=f\"{filename}.log\")\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "\n",
    "def get_scheduler(cfg, optimizer, num_train_steps):\n",
    "    if cfg.SCHEDULER == 'linear':\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer, num_warmup_steps=cfg.NUM_WARMUP_STEPS,\n",
    "            num_training_steps=num_train_steps\n",
    "        )\n",
    "    elif cfg.SCHEDULER == 'cosine':\n",
    "        scheduler = get_cosine_schedule_with_warmup(\n",
    "            optimizer, num_warmup_steps=cfg.NUM_WARMUP_STEPS,\n",
    "            num_training_steps=num_train_steps, num_cycles=cfg.NUM_CYCLES\n",
    "        )\n",
    "    return scheduler\n",
    "    \n",
    "\n",
    "def get_score(y_trues, y_preds):\n",
    "    score = roc_auc_score(y_trues, y_preds)\n",
    "    return score\n",
    "\n",
    "\n",
    "def seed_everything(seed=20):\n",
    "    \"\"\"Seed everything to ensure reproducibility\"\"\"\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "\n",
    "def sep():\n",
    "    print(\"-\"*100)\n",
    "    \n",
    "    \n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))  \n",
    "    \n",
    "LOGGER = get_logger()\n",
    "seed_everything(seed=config.SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b><span style='color:#F1A424'>|</span> Weights and Biases üêù</b><a class='anchor' id='wandb'></a> [‚Üë](#top) \n",
    "\n",
    "***\n",
    "\n",
    "Weights and Biases for tracking experiments. Change the `WANDB` flag in the configuration class if you want to track your experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "notes = \"\"\n",
    "\n",
    "if config.WANDB:\n",
    "    try:\n",
    "        from kaggle_secrets import UserSecretsClient\n",
    "        user_secrets = UserSecretsClient()\n",
    "        wandb.login(key='eed81e1c0a41dd8dd67a4ca90cea1be5a06d4eb0')\n",
    "        anony = None\n",
    "    except:\n",
    "        anony = \"must\"\n",
    "        print('If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \\nGet your W&B access token from here: https://wandb.ai/authorize')\n",
    "\n",
    "    run = wandb.init(project='DS_Termproject', \n",
    "                     name=\"DeBERTa\",\n",
    "                     entity='hcim',\n",
    "                     config=get_config_dict(config),\n",
    "                     job_type=\"train\",\n",
    "                     notes=notes,\n",
    "                     anonymous=anony)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012589,
     "end_time": "2022-08-31T07:03:04.13341",
     "exception": false,
     "start_time": "2022-08-31T07:03:04.120821",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <b><span style='color:#F1A424'>|</span> Load Data</b><a class='anchor' id='load_data'></a> [‚Üë](#top) \n",
    "\n",
    "***\n",
    "\n",
    "Load data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "papermill": {
     "duration": 0.242687,
     "end_time": "2022-08-31T07:03:04.383434",
     "exception": false,
     "start_time": "2022-08-31T07:03:04.140747",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train essays dataframe has shape: (1378, 4)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "External essays dataframe has shape: (2421, 4)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Train prompts dataframe has shape: (2, 4)\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0059830c</td>\n",
       "      <td>0</td>\n",
       "      <td>Cars. Cars have been around since they became ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>005db917</td>\n",
       "      <td>0</td>\n",
       "      <td>Transportation is a large necessity in most co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>008f63e3</td>\n",
       "      <td>0</td>\n",
       "      <td>\"America's love affair with it's vehicles seem...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00940276</td>\n",
       "      <td>0</td>\n",
       "      <td>How often do you ride in a car? Do you drive a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00c39458</td>\n",
       "      <td>0</td>\n",
       "      <td>Cars are a wonderful thing. They are perhaps o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  prompt_id                                               text  generated\n",
       "0  0059830c          0  Cars. Cars have been around since they became ...          0\n",
       "1  005db917          0  Transportation is a large necessity in most co...          0\n",
       "2  008f63e3          0  \"America's love affair with it's vehicles seem...          0\n",
       "3  00940276          0  How often do you ride in a car? Do you drive a...          0\n",
       "4  00c39458          0  Cars are a wonderful thing. They are perhaps o...          0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>instructions</th>\n",
       "      <th>source_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6060D28C05B6</td>\n",
       "      <td>Some schools in United States ofter classes fr...</td>\n",
       "      <td>\\nTask: Write a persuasive essay on whether or...</td>\n",
       "      <td>\\nWhen considering the pros and cons of attend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60623DB5DE7A</td>\n",
       "      <td>Four-day work week, a remarkable idea to conse...</td>\n",
       "      <td>\\nTask: Research the advantages and disadvanta...</td>\n",
       "      <td>\\nOne of the primary arguments for implementin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>607A39D981DE</td>\n",
       "      <td>Students and their families should consider an...</td>\n",
       "      <td>\\nTask: \\n\\n1. Talk to your parents before tak...</td>\n",
       "      <td>\\nBefore making any decisions about getting in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60ACDFA1609E</td>\n",
       "      <td>Agree you will never grow if something beyond ...</td>\n",
       "      <td>\\nTask: Write an essay discussing the benefits...</td>\n",
       "      <td>\\nRalph Waldo Emerson once said, \"Go confident...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60AE13D3F07B</td>\n",
       "      <td>I think our character traits are formed by inf...</td>\n",
       "      <td>\\nTask: Research and discuss how character tra...</td>\n",
       "      <td>\\nHuman character traits are shaped by a wide ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                               text                                       instructions                                        source_text\n",
       "0  6060D28C05B6  Some schools in United States ofter classes fr...  \\nTask: Write a persuasive essay on whether or...  \\nWhen considering the pros and cons of attend...\n",
       "1  60623DB5DE7A  Four-day work week, a remarkable idea to conse...  \\nTask: Research the advantages and disadvanta...  \\nOne of the primary arguments for implementin...\n",
       "2  607A39D981DE  Students and their families should consider an...  \\nTask: \\n\\n1. Talk to your parents before tak...  \\nBefore making any decisions about getting in...\n",
       "3  60ACDFA1609E  Agree you will never grow if something beyond ...  \\nTask: Write an essay discussing the benefits...  \\nRalph Waldo Emerson once said, \"Go confident...\n",
       "4  60AE13D3F07B  I think our character traits are formed by inf...  \\nTask: Research and discuss how character tra...  \\nHuman character traits are shaped by a wide ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>prompt_name</th>\n",
       "      <th>instructions</th>\n",
       "      <th>source_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Car-free cities</td>\n",
       "      <td>Write an explanatory essay to inform fellow ci...</td>\n",
       "      <td># In German Suburb, Life Goes On Without Cars ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Does the electoral college work?</td>\n",
       "      <td>Write a letter to your state senator in which ...</td>\n",
       "      <td># What Is the Electoral College? by the Office...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prompt_id                       prompt_name                                       instructions                                        source_text\n",
       "0          0                   Car-free cities  Write an explanatory essay to inform fellow ci...  # In German Suburb, Life Goes On Without Cars ...\n",
       "1          1  Does the electoral college work?  Write a letter to your state senator in which ...  # What Is the Electoral College? by the Office..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df = pd.read_csv(paths.TRAIN_ESSAYS, sep=',')\n",
    "external_df = pd.read_csv(paths.EXTERNAL_DATA, sep=',')\n",
    "train_prompts = pd.read_csv(paths.TRAIN_PROMPTS, sep=',')\n",
    "print(f\"Train essays dataframe has shape: {train_df.shape}\"), sep()\n",
    "print(f\"External essays dataframe has shape: {external_df.shape}\"), sep()\n",
    "print(f\"Train prompts dataframe has shape: {train_prompts.shape}\"), sep()\n",
    "display(train_df.head())\n",
    "display(external_df.head())\n",
    "display(train_prompts.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b><span style='color:#F1A424'>Add External Data</span></b>\n",
    "\n",
    "We will use the external data to train our model:\n",
    "- `source_text` is AI-generated\n",
    "- `text` is student-written texts from FeedBack prize 3 competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataframe has shape: (6220, 3)\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0059830c</td>\n",
       "      <td>Cars. Cars have been around since they became ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>005db917</td>\n",
       "      <td>Transportation is a large necessity in most co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>008f63e3</td>\n",
       "      <td>\"America's love affair with it's vehicles seem...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00940276</td>\n",
       "      <td>How often do you ride in a car? Do you drive a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00c39458</td>\n",
       "      <td>Cars are a wonderful thing. They are perhaps o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               text  generated\n",
       "0  0059830c  Cars. Cars have been around since they became ...          0\n",
       "1  005db917  Transportation is a large necessity in most co...          0\n",
       "2  008f63e3  \"America's love affair with it's vehicles seem...          0\n",
       "3  00940276  How often do you ride in a car? Do you drive a...          0\n",
       "4  00c39458  Cars are a wonderful thing. They are perhaps o...          0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "external_df1 = external_df[[\"id\", \"source_text\"]]\n",
    "external_df1.columns = [\"id\", \"text\"]\n",
    "external_df1['text'] = external_df['text'].str.replace('\\n', '')\n",
    "external_df1[\"generated\"] = 1\n",
    "external_df2 = external_df[[\"id\", \"text\"]]\n",
    "external_df2[\"generated\"] = 0\n",
    "\n",
    "train_df.drop(columns=[\"prompt_id\"],inplace=True)\n",
    "train_df = pd.concat([train_df, external_df1, external_df2])\n",
    "train_df.reset_index(inplace=True, drop=True)\n",
    "print(f\"Train dataframe has shape: {train_df.shape}\"), sep()\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.008293,
     "end_time": "2022-08-31T07:03:04.40102",
     "exception": false,
     "start_time": "2022-08-31T07:03:04.392727",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <b><span style='color:#F1A424'>|</span> Validation</b><a class='anchor' id='validation'></a> [‚Üë](#top) \n",
    "\n",
    "***\n",
    "\n",
    "We will use a `StratifiedKFold` partition, stratifying by `generated`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "papermill": {
     "duration": 0.148391,
     "end_time": "2022-08-31T07:03:04.558882",
     "exception": false,
     "start_time": "2022-08-31T07:03:04.410491",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold  generated\n",
      "0.0   0            760\n",
      "      1            484\n",
      "1.0   0            759\n",
      "      1            485\n",
      "2.0   0            759\n",
      "      1            485\n",
      "3.0   0            759\n",
      "      1            485\n",
      "4.0   0            759\n",
      "      1            485\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0059830c</td>\n",
       "      <td>Cars. Cars have been around since they became ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>005db917</td>\n",
       "      <td>Transportation is a large necessity in most co...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>008f63e3</td>\n",
       "      <td>\"America's love affair with it's vehicles seem...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00940276</td>\n",
       "      <td>How often do you ride in a car? Do you drive a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00c39458</td>\n",
       "      <td>Cars are a wonderful thing. They are perhaps o...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               text  generated  fold\n",
       "0  0059830c  Cars. Cars have been around since they became ...          0   0.0\n",
       "1  005db917  Transportation is a large necessity in most co...          0   0.0\n",
       "2  008f63e3  \"America's love affair with it's vehicles seem...          0   0.0\n",
       "3  00940276  How often do you ride in a car? Do you drive a...          0   0.0\n",
       "4  00c39458  Cars are a wonderful thing. They are perhaps o...          0   0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "X = train_df.loc[:, train_df.columns != \"generated\"]\n",
    "y = train_df.loc[:, train_df.columns == \"generated\"]\n",
    "\n",
    "for i, (train_index, valid_index) in enumerate(skf.split(X, y)):\n",
    "    train_df.loc[valid_index, \"fold\"] = i\n",
    "    \n",
    "print(train_df.groupby(\"fold\")[\"generated\"].value_counts())\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.007561,
     "end_time": "2022-08-31T07:03:04.604916",
     "exception": false,
     "start_time": "2022-08-31T07:03:04.597355",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <b><span style='color:#F1A424'>|</span> Tokenizer</b><a class='anchor' id='tokenizer'></a> [‚Üë](#top) \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "papermill": {
     "duration": 7.351568,
     "end_time": "2022-08-31T07:03:11.964298",
     "exception": false,
     "start_time": "2022-08-31T07:03:04.61273",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XLMRobertaTokenizerFast(name_or_path='bettertextapp/gpt2-large-detector-de-v1', vocab_size=250002, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>', 'additional_special_tokens': ['<null>']}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t1: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t3: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t250001: AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False, special=True),\n",
      "\t250002: AddedToken(\"<null>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(config.MODEL)\n",
    "tokenizer.save_pretrained(paths.OUTPUT_DIR + '/tokenizer/')\n",
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.008127,
     "end_time": "2022-08-31T07:03:11.985369",
     "exception": false,
     "start_time": "2022-08-31T07:03:11.977242",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <b><span style='color:#F1A424'>|</span> Dataset</b><a class='anchor' id='dataset'></a> [‚Üë](#top) \n",
    "\n",
    "***\n",
    "\n",
    "    \n",
    "We need to get the `max_len` from our `tokenizer`. We create a `tqdm` iterator and for each text we extract the tokenized length. Then we get the maximum value and we add 3 for the special tokens `CLS`, `SEP`, `SEP`.\n",
    "\n",
    "- [Hugging Face Padding and Truncation](https://huggingface.co/docs/transformers/pad_truncation): check truncation to `max_length` or `True` (batch max length)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "papermill": {
     "duration": 5.893032,
     "end_time": "2022-08-31T07:03:17.886504",
     "exception": false,
     "start_time": "2022-08-31T07:03:11.993472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2096f55ee27e426e8ed28b3108d833a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6220 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (786 > 512). Running this sequence through the model will result in indexing errors\n",
      "max_len: 512\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "lengths = []\n",
    "tqdm_loader = tqdm(train_df['text'].fillna(\"\").values, total=len(train_df))\n",
    "for text in tqdm_loader:\n",
    "    length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n",
    "    lengths.append(length)\n",
    "\n",
    "# config.MAX_LEN = max(lengths) + 3 # cls & sep & sep\n",
    "LOGGER.info(f\"max_len: {config.MAX_LEN}\")\n",
    "plt.hist(lengths, bins=25)\n",
    "plt.xlabel('Token Length')  # x Î†àÏù¥Î∏î Ï∂îÍ∞Ä\n",
    "plt.ylabel('Frequency')     # y Î†àÏù¥Î∏î Ï∂îÍ∞Ä\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "papermill": {
     "duration": 0.020447,
     "end_time": "2022-08-31T07:03:17.916566",
     "exception": false,
     "start_time": "2022-08-31T07:03:17.896119",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_input(cfg, text, tokenizer):\n",
    "    \"\"\"\n",
    "    This function tokenizes the input text with the configured padding and truncation. Then,\n",
    "    returns the input dictionary, which contains the following keys: \"input_ids\",\n",
    "    \"token_type_ids\" and \"attention_mask\". Each value is a torch.tensor.\n",
    "    :param cfg: configuration class with a TOKENIZER attribute.\n",
    "    :param text: a numpy array where each value is a text as string.\n",
    "    :return inputs: python dictionary where values are torch tensors.\n",
    "    \"\"\"\n",
    "    inputs = tokenizer.encode_plus(\n",
    "        text, \n",
    "        return_tensors=None, \n",
    "        add_special_tokens=True, \n",
    "        max_length=cfg.MAX_LEN,\n",
    "        padding='max_length', # TODO: check padding to max sequence in batch\n",
    "        truncation=True\n",
    "    )\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = torch.tensor(v, dtype=torch.long) # TODO: check dtypes\n",
    "    return inputs\n",
    "\n",
    "\n",
    "def collate(inputs):\n",
    "    \"\"\"\n",
    "    It truncates the inputs to the maximum sequence length in the batch. \n",
    "    \"\"\"\n",
    "    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max()) # Get batch's max sequence length\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = inputs[k][:,:mask_len]\n",
    "    return inputs\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, cfg, df, tokenizer):\n",
    "        self.cfg = cfg\n",
    "        self.texts = df['text'].values\n",
    "        self.labels = df['generated'].values\n",
    "        self.tokenizer = tokenizer\n",
    "        self.text_ids = df['id'].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        output = {}\n",
    "        output[\"inputs\"] = prepare_input(self.cfg, self.texts[item], self.tokenizer)\n",
    "        output[\"labels\"] = torch.tensor(self.labels[item], dtype=torch.float) # TODO: check dtypes\n",
    "        output[\"ids\"] = self.text_ids[item]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One sample from the dataset should look as following:\n",
    "```python\n",
    "{\n",
    "\t'inputs': {\n",
    "\t\t'input_ids': tensor([1, 279, 883, ..., 0, 0]),\n",
    "\t\t'token_type_ids': tensor([0, 0, 0, ..., 0, 0]),\n",
    "\t\t'attention_mask': tensor([1, 1, 1, ..., 0, 0])\n",
    "\t},\n",
    "\t'label': tensor([0.0]),\n",
    "\t'ids': '000e8c3c7ddb'\n",
    "}\n",
    "```\n",
    "You can check it by running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if config.DEBUG:\n",
    "    # ======== SPLIT ==========\n",
    "    fold = 0\n",
    "    train_folds = train_df[train_df['fold'] != fold].reset_index(drop=True)\n",
    "    valid_folds = train_df[train_df['fold'] == fold].reset_index(drop=True)\n",
    "    valid_labels = valid_folds['generated'].values\n",
    "\n",
    "    # ======== DATASETS ==========\n",
    "    train_dataset = CustomDataset(config, train_folds, tokenizer)\n",
    "    valid_dataset = CustomDataset(config, valid_folds, tokenizer)\n",
    "\n",
    "    # ======== DATALOADERS ==========\n",
    "    train_loader = DataLoader(train_dataset,\n",
    "                              batch_size=config.BATCH_SIZE_TRAIN, # TODO: split into train and valid\n",
    "                              shuffle=True,\n",
    "                              num_workers=config.NUM_WORKERS, pin_memory=True, drop_last=True)\n",
    "    valid_loader = DataLoader(valid_dataset,\n",
    "                              batch_size=config.BATCH_SIZE_VALID,\n",
    "                              shuffle=False,\n",
    "                              num_workers=config.NUM_WORKERS, pin_memory=True, drop_last=False)\n",
    "\n",
    "    # === Let's check one sample ===\n",
    "    sample = train_dataset[0]\n",
    "    print(f\"Encoding keys: {sample.keys()} \\n\") \n",
    "    print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.008073,
     "end_time": "2022-08-31T07:03:17.933189",
     "exception": false,
     "start_time": "2022-08-31T07:03:17.925116",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <b><span style='color:#F1A424'>|</span> Model</b><a class='anchor' id='model'></a> [‚Üë](#top) \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "papermill": {
     "duration": 0.033105,
     "end_time": "2022-08-31T07:03:17.97447",
     "exception": false,
     "start_time": "2022-08-31T07:03:17.941365",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MeanPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MeanPooling, self).__init__()\n",
    "        \n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n",
    "        sum_mask = input_mask_expanded.sum(1)\n",
    "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
    "        mean_embeddings = sum_embeddings / sum_mask\n",
    "        return mean_embeddings\n",
    "    \n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, cfg, config_path=None, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.dropout = 0.2\n",
    "        # Load config by inferencing it from the model name.\n",
    "        if config_path is None: \n",
    "            self.config = AutoConfig.from_pretrained(cfg.MODEL, output_hidden_states=True)\n",
    "            self.config.hidden_dropout = 0.\n",
    "            self.config.hidden_dropout_prob = 0.\n",
    "            self.config.attention_dropout = 0.\n",
    "            self.config.attention_probs_dropout_prob = 0.\n",
    "        # Load config from a file.\n",
    "        else:\n",
    "            self.config = torch.load(config_path)\n",
    "        \n",
    "        if pretrained:\n",
    "            self.model = AutoModel.from_pretrained(cfg.MODEL, config=self.config)\n",
    "        else:\n",
    "            self.model = AutoModel(self.config)\n",
    "        \n",
    "        if self.cfg.GRADIENT_CHECKPOINTING:\n",
    "            self.model.gradient_checkpointing_enable()\n",
    "          \n",
    "        # Add MeanPooling and Linear head at the end to transform the Model into a RegressionModel\n",
    "        self.pool = MeanPooling() # MetaFormerÏóêÏÑú ÏÇ¨Ïö©Îêú Pooling ÏïÑÏù¥ÎîîÏñ¥ÏóêÏÑú Ï∞©Ïïà.\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(self.config.hidden_size, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Mish(),\n",
    "            nn.Dropout(self.dropout),\n",
    "            nn.Linear(64, 16),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.Mish(),\n",
    "            nn.Dropout(self.dropout),\n",
    "            nn.Linear(16, 1)\n",
    "        )\n",
    "        self._init_weights(self.head)\n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        \"\"\"\n",
    "        This method initializes weights for different types of layers. The type of layers \n",
    "        supported are nn.Linear, nn.Embedding and nn.LayerNorm.\n",
    "        \"\"\"\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "        \n",
    "    def feature(self, inputs):\n",
    "        \"\"\"\n",
    "        This method makes a forward pass through the model, get the last hidden state (embedding)\n",
    "        and pass it through the MeanPooling layer.\n",
    "        \"\"\"\n",
    "        outputs = self.model(**inputs)\n",
    "        last_hidden_states = outputs[0]\n",
    "        feature = self.pool(last_hidden_states, inputs['attention_mask'])\n",
    "        return feature\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        This method makes a forward pass through the model, the MeanPooling layer and finally\n",
    "        then through the Linear layer to get a regression value.\n",
    "        \"\"\"\n",
    "        feature = self.feature(inputs)\n",
    "        output = self.head(feature)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.008452,
     "end_time": "2022-08-31T07:03:18.041557",
     "exception": false,
     "start_time": "2022-08-31T07:03:18.033105",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <b><span style='color:#F1A424'>|</span> Train and Validation Functions</b><a class='anchor' id='functions'></a> [‚Üë](#top) \n",
    "\n",
    "***\n",
    "    \n",
    "- [torch.cuda.amp.GradScaler](https://pytorch.org/docs/stable/amp.html#torch.cuda.amp.GradScaler): This class helps writing compute efficient training loops, so we dont get OOM errors. Also, one common error in any large deep learning model is the problem of underflowing gradients (i.e. your gradients are too small to take into account). `float16` tensors often don't take into account extremely small variations. To prevent this we can scale our gradients by some factor so that they aren't flushed to zero. Not to be confused with vanishing gradients, this gradients still might contribute to the learning process however are skipped because of computational limits.\n",
    "- [torch.autocast](https://pytorch.org/docs/stable/amp.html#torch.autocast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "papermill": {
     "duration": 0.030759,
     "end_time": "2022-08-31T07:03:18.08056",
     "exception": false,
     "start_time": "2022-08-31T07:03:18.049801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "\n",
    "def train_epoch(train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
    "    \"\"\"One epoch training pass.\"\"\"\n",
    "    model.train() # set model in train mode\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=config.APEX) # Automatic Mixed Precision tries to match each op to its appropriate datatype.\n",
    "    losses = AverageMeter() # initiate AverageMeter to track the loss.\n",
    "    start = end = time.time() # track the execution time.\n",
    "    global_step = 0\n",
    "    \n",
    "    # ========== ITERATE OVER TRAIN BATCHES ============\n",
    "    with tqdm(train_loader, unit=\"train_batch\", desc='Train') as tqdm_train_loader:\n",
    "        for step, batch in enumerate(tqdm_train_loader):\n",
    "            inputs = batch.pop(\"inputs\")\n",
    "            labels = batch.pop(\"labels\")\n",
    "            inputs = collate(inputs) # collate inputs\n",
    "            for k, v in inputs.items(): # send each tensor value to `device`\n",
    "                inputs[k] = v.to(device)\n",
    "            labels = labels.to(device) # send labels to `device`\n",
    "            batch_size = labels.size(0)\n",
    "            with torch.cuda.amp.autocast(enabled=config.APEX):\n",
    "                y_preds = model(inputs) # forward propagation pass\n",
    "                loss = criterion(y_preds, labels.unsqueeze(1)) # get loss\n",
    "            if config.GRADIENT_ACCUMULATION_STEPS > 1:\n",
    "                loss = loss / config.GRADIENT_ACCUMULATION_STEPS\n",
    "            losses.update(loss.item(), batch_size) # update loss function tracking\n",
    "            scaler.scale(loss).backward() # backward propagation pass\n",
    "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), config.MAX_GRAD_NORM)\n",
    "\n",
    "            if (step + 1) % config.GRADIENT_ACCUMULATION_STEPS == 0:\n",
    "                scaler.step(optimizer) # update optimizer parameters\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad() # zero out the gradients\n",
    "                global_step += 1\n",
    "                if config.BATCH_SCHEDULER:\n",
    "                    scheduler.step() # update learning rate\n",
    "            end = time.time() # get finish time\n",
    "\n",
    "            # ========== LOG INFO ==========\n",
    "            if step % config.PRINT_FREQ == 0 or step == (len(train_loader)-1):\n",
    "                print('Epoch: [{0}][{1}/{2}] '\n",
    "                      'Elapsed {remain:s} '\n",
    "                      'Loss: {loss.avg:.4f} '\n",
    "                      'Grad: {grad_norm:.4f}  '\n",
    "                      'LR: {lr:.8f}  '\n",
    "                      .format(epoch+1, step, len(train_loader), \n",
    "                              remain=timeSince(start, float(step+1)/len(train_loader)),\n",
    "                              loss=losses,\n",
    "                              grad_norm=grad_norm,\n",
    "                              lr=scheduler.get_lr()[0]))\n",
    "            if config.WANDB:\n",
    "                wandb.log({f\"[fold_{fold}] train loss\": losses.val,\n",
    "                           f\"[fold_{fold}] lr\": scheduler.get_lr()[0]})\n",
    "\n",
    "    return losses.avg\n",
    "\n",
    "\n",
    "def valid_epoch(valid_loader, model, criterion, device):\n",
    "    model.eval() # set model in evaluation mode\n",
    "    losses = AverageMeter() # initiate AverageMeter for tracking the loss.\n",
    "    prediction_dict = {}\n",
    "    preds = []\n",
    "    start = end = time.time() # track the execution time.\n",
    "    with tqdm(valid_loader, unit=\"valid_batch\", desc='Validation') as tqdm_valid_loader:\n",
    "        for step, batch in enumerate(tqdm_valid_loader):\n",
    "            inputs = batch.pop(\"inputs\")\n",
    "            labels = batch.pop(\"labels\")\n",
    "            ids = batch.pop(\"ids\")\n",
    "            inputs = collate(inputs) # collate inputs\n",
    "            for k, v in inputs.items():\n",
    "                inputs[k] = v.to(device) # send inputs to device\n",
    "            labels = labels.to(device)\n",
    "            batch_size = labels.size(0)\n",
    "            with torch.no_grad():\n",
    "                y_preds = model(inputs) # forward propagation pass\n",
    "                loss = criterion(y_preds, labels.unsqueeze(1)) # get loss\n",
    "            if config.GRADIENT_ACCUMULATION_STEPS > 1:\n",
    "                loss = loss / config.GRADIENT_ACCUMULATION_STEPS\n",
    "            losses.update(loss.item(), batch_size) # update loss function tracking\n",
    "            preds.append(y_preds.to('cpu').numpy()) # save predictions\n",
    "            end = time.time() # get finish time\n",
    "\n",
    "            # ========== LOG INFO ==========\n",
    "            if step % config.PRINT_FREQ == 0 or step == (len(valid_loader)-1):\n",
    "                print('EVAL: [{0}/{1}] '\n",
    "                      'Elapsed {remain:s} '\n",
    "                      'Loss: {loss.avg:.4f} '\n",
    "                      .format(step, len(valid_loader),\n",
    "                              loss=losses,\n",
    "                              remain=timeSince(start, float(step+1)/len(valid_loader))))\n",
    "            if config.WANDB:\n",
    "                wandb.log({f\"[fold_{fold}] val loss\": losses.val})\n",
    "                \n",
    "    prediction_dict[\"predictions\"] = np.concatenate(preds) # np.array() of shape (fold_size, target_cols)\n",
    "    prediction_dict[\"ids\"] = ids\n",
    "    return losses.avg, prediction_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.0081,
     "end_time": "2022-08-31T07:03:18.100232",
     "exception": false,
     "start_time": "2022-08-31T07:03:18.092132",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <b><span style='color:#F1A424'>|</span> Train Loop</b><a class='anchor' id='train_loop'></a> [‚Üë](#top) \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "papermill": {
     "duration": 0.033332,
     "end_time": "2022-08-31T07:03:18.141812",
     "exception": false,
     "start_time": "2022-08-31T07:03:18.10848",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_loop(folds, fold):\n",
    "    \n",
    "    LOGGER.info(f\"========== Fold: {fold} training ==========\")\n",
    "\n",
    "    # ======== SPLIT ==========\n",
    "    train_folds = folds[folds['fold'] != fold].reset_index(drop=True)\n",
    "    valid_folds = folds[folds['fold'] == fold].reset_index(drop=True)\n",
    "\n",
    "    valid_labels = valid_folds['generated'].values\n",
    "\n",
    "    # ======== DATASETS ==========\n",
    "    train_dataset = CustomDataset(config, train_folds, tokenizer)\n",
    "    valid_dataset = CustomDataset(config, valid_folds, tokenizer)\n",
    "    \n",
    "    # ======== DATALOADERS ==========\n",
    "    train_loader = DataLoader(train_dataset,\n",
    "                              batch_size=config.BATCH_SIZE_TRAIN, # TODO: split into train and valid\n",
    "                              shuffle=True,\n",
    "                              pin_memory=True, drop_last=True)\n",
    "    valid_loader = DataLoader(valid_dataset,\n",
    "                              batch_size=config.BATCH_SIZE_VALID,\n",
    "                              shuffle=False,\n",
    "                              pin_memory=True, drop_last=False)\n",
    "    \n",
    "    # ======== MODEL ==========\n",
    "    model = CustomModel(config, config_path=None, pretrained=True)\n",
    "    torch.save(model.config, paths.OUTPUT_DIR + '/config.pth')\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer_parameters = get_optimizer_params(model,\n",
    "                                                encoder_lr=config.ENCODER_LR, \n",
    "                                                decoder_lr=config.DECODER_LR,\n",
    "                                                weight_decay=config.WEIGHT_DECAY)\n",
    "    optimizer = AdamW(optimizer_parameters,\n",
    "                      lr=config.ENCODER_LR,\n",
    "                      eps=config.EPS,\n",
    "                      betas=config.BETAS)\n",
    "    \n",
    "    scheduler = OneCycleLR(\n",
    "        optimizer,\n",
    "        max_lr=1e-5,\n",
    "        epochs=config.EPOCHS,\n",
    "        steps_per_epoch=len(train_loader),\n",
    "        pct_start=0.1,\n",
    "        anneal_strategy=\"cos\",\n",
    "        final_div_factor=100,\n",
    "    )\n",
    "\n",
    "    # ======= LOSS ==========\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    best_score = -np.inf\n",
    "    # ====== ITERATE EPOCHS ========\n",
    "    for epoch in range(config.EPOCHS):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # ======= TRAIN ==========\n",
    "        avg_loss = train_epoch(train_loader, model, criterion, optimizer, epoch, scheduler, device)\n",
    "\n",
    "        # ======= EVALUATION ==========\n",
    "        avg_val_loss, prediction_dict = valid_epoch(valid_loader, model, criterion, device)\n",
    "        predictions = prediction_dict[\"predictions\"]\n",
    "        # ======= SCORING ==========\n",
    "        score = get_score(valid_labels, sigmoid(predictions))\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n",
    "        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}')\n",
    "        \n",
    "        if config.WANDB:\n",
    "            wandb.log({f\"[fold_{fold}] epoch\": epoch+1, \n",
    "                       f\"[fold_{fold}] avg_train_loss\": avg_loss, \n",
    "                       f\"[fold_{fold}] avg_val_loss\": avg_val_loss,\n",
    "                       f\"[fold_{fold}] score\": score})\n",
    "            \n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n",
    "            torch.save(model.state_dict(),\n",
    "                        paths.OUTPUT_DIR + f\"/{config.MODEL.replace('/', '_')}_fold_{fold}_best.pth\")\n",
    "            best_model_predictions = predictions\n",
    "\n",
    "    valid_folds[\"preds\"] = best_model_predictions\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    return valid_folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b><span style='color:#F1A424'>|</span> Train</b><a class='anchor' id='train'></a> [‚Üë](#top) \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "papermill": {
     "duration": 11935.46951,
     "end_time": "2022-08-31T10:22:13.621316",
     "exception": false,
     "start_time": "2022-08-31T07:03:18.151806",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== Fold: 0 training ==========\n",
      "Some weights of XLMRobertaModel were not initialized from the model checkpoint at bettertextapp/gpt2-large-detector-de-v1 and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd9c64c9894d48bc99033be501e9457b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/155 [00:00<?, ?train_batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/155] Elapsed 0m 1s (remain 3m 17s) Loss: 0.8088 Grad: inf  LR: 0.00000040  \n",
      "Epoch: [1][20/155] Elapsed 0m 12s (remain 1m 19s) Loss: 0.7734 Grad: 225518.7969  LR: 0.00000208  \n",
      "Epoch: [1][40/155] Elapsed 0m 23s (remain 1m 5s) Loss: 0.7567 Grad: 117376.4062  LR: 0.00000574  \n",
      "Epoch: [1][60/155] Elapsed 0m 34s (remain 0m 53s) Loss: 0.7502 Grad: 349905.9375  LR: 0.00000906  \n",
      "Epoch: [1][80/155] Elapsed 0m 45s (remain 0m 41s) Loss: 0.7316 Grad: 110122.1953  LR: 0.00001000  \n",
      "Epoch: [1][100/155] Elapsed 0m 56s (remain 0m 30s) Loss: 0.6921 Grad: 64910.0234  LR: 0.00000997  \n",
      "Epoch: [1][120/155] Elapsed 1m 8s (remain 0m 19s) Loss: 0.6523 Grad: 56651.7266  LR: 0.00000990  \n",
      "Epoch: [1][140/155] Elapsed 1m 19s (remain 0m 7s) Loss: 0.6217 Grad: 38152.5859  LR: 0.00000979  \n",
      "Epoch: [1][154/155] Elapsed 1m 27s (remain 0m 0s) Loss: 0.6045 Grad: 31080.9336  LR: 0.00000969  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a290f7d522c48958968fe821d125823",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/78 [00:00<?, ?valid_batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/78] Elapsed 0m 0s (remain 0m 17s) Loss: 0.4537 \n",
      "EVAL: [20/78] Elapsed 0m 4s (remain 0m 11s) Loss: 0.4740 \n",
      "EVAL: [40/78] Elapsed 0m 8s (remain 0m 7s) Loss: 0.4888 \n",
      "EVAL: [60/78] Elapsed 0m 12s (remain 0m 3s) Loss: 0.4322 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.6045  avg_val_loss: 0.3887  time: 103s\n",
      "Epoch 1 - Score: 0.9945\n",
      "Epoch 1 - Save Best Score: 0.9945 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [77/78] Elapsed 0m 15s (remain 0m 0s) Loss: 0.3887 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba535ea9ff5546b9801bb13795ad8754",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/155 [00:00<?, ?train_batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/155] Elapsed 0m 0s (remain 1m 28s) Loss: 0.4842 Grad: 122549.4453  LR: 0.00000968  \n",
      "Epoch: [2][20/155] Elapsed 0m 11s (remain 1m 15s) Loss: 0.4503 Grad: 66963.7031  LR: 0.00000951  \n",
      "Epoch: [2][40/155] Elapsed 0m 23s (remain 1m 3s) Loss: 0.4401 Grad: 56319.5938  LR: 0.00000929  \n",
      "Epoch: [2][60/155] Elapsed 0m 34s (remain 0m 52s) Loss: 0.4391 Grad: 48011.4023  LR: 0.00000905  \n",
      "Epoch: [2][80/155] Elapsed 0m 45s (remain 0m 41s) Loss: 0.4347 Grad: 68653.9844  LR: 0.00000876  \n",
      "Epoch: [2][100/155] Elapsed 0m 56s (remain 0m 30s) Loss: 0.4314 Grad: 93508.2734  LR: 0.00000845  \n",
      "Epoch: [2][120/155] Elapsed 1m 7s (remain 0m 19s) Loss: 0.4291 Grad: 54695.6562  LR: 0.00000811  \n",
      "Epoch: [2][140/155] Elapsed 1m 19s (remain 0m 7s) Loss: 0.4277 Grad: 49031.1562  LR: 0.00000775  \n",
      "Epoch: [2][154/155] Elapsed 1m 26s (remain 0m 0s) Loss: 0.4260 Grad: 120828.8359  LR: 0.00000748  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8463709db80c41dea69db6b4e429077e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/78 [00:00<?, ?valid_batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/78] Elapsed 0m 0s (remain 0m 16s) Loss: 0.4589 \n",
      "EVAL: [20/78] Elapsed 0m 4s (remain 0m 11s) Loss: 0.4629 \n",
      "EVAL: [40/78] Elapsed 0m 8s (remain 0m 7s) Loss: 0.4707 \n",
      "EVAL: [60/78] Elapsed 0m 12s (remain 0m 3s) Loss: 0.4184 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.4260  avg_val_loss: 0.3772  time: 103s\n",
      "Epoch 2 - Score: 0.9967\n",
      "Epoch 2 - Save Best Score: 0.9967 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [77/78] Elapsed 0m 15s (remain 0m 0s) Loss: 0.3772 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c3489fe41724971817e828317047097",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/155 [00:00<?, ?train_batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/155] Elapsed 0m 0s (remain 1m 42s) Loss: 0.4282 Grad: 51969.2773  LR: 0.00000746  \n",
      "Epoch: [3][20/155] Elapsed 0m 11s (remain 1m 15s) Loss: 0.4126 Grad: 55040.0234  LR: 0.00000706  \n",
      "Epoch: [3][40/155] Elapsed 0m 23s (remain 1m 4s) Loss: 0.4149 Grad: 46969.2891  LR: 0.00000664  \n",
      "Epoch: [3][60/155] Elapsed 0m 34s (remain 0m 52s) Loss: 0.4149 Grad: 47473.3984  LR: 0.00000621  \n",
      "Epoch: [3][80/155] Elapsed 0m 45s (remain 0m 41s) Loss: 0.4133 Grad: 85126.5859  LR: 0.00000577  \n",
      "Epoch: [3][100/155] Elapsed 0m 56s (remain 0m 30s) Loss: 0.4145 Grad: 53554.4531  LR: 0.00000532  \n",
      "Epoch: [3][120/155] Elapsed 1m 7s (remain 0m 19s) Loss: 0.4123 Grad: 59747.1367  LR: 0.00000487  \n",
      "Epoch: [3][140/155] Elapsed 1m 19s (remain 0m 7s) Loss: 0.4116 Grad: 43450.1484  LR: 0.00000442  \n",
      "Epoch: [3][154/155] Elapsed 1m 27s (remain 0m 0s) Loss: 0.4109 Grad: 82514.9609  LR: 0.00000411  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4e344c08c2746359a67f8023c21f896",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/78 [00:00<?, ?valid_batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/78] Elapsed 0m 0s (remain 0m 16s) Loss: 0.4395 \n",
      "EVAL: [20/78] Elapsed 0m 4s (remain 0m 11s) Loss: 0.4418 \n",
      "EVAL: [40/78] Elapsed 0m 8s (remain 0m 7s) Loss: 0.4486 \n",
      "EVAL: [60/78] Elapsed 0m 12s (remain 0m 3s) Loss: 0.4054 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.4109  avg_val_loss: 0.3715  time: 103s\n",
      "Epoch 3 - Score: 0.9970\n",
      "Epoch 3 - Save Best Score: 0.9970 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [77/78] Elapsed 0m 15s (remain 0m 0s) Loss: 0.3715 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38d716a512364849882ff64ebd4ebc7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/155 [00:00<?, ?train_batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/155] Elapsed 0m 0s (remain 1m 41s) Loss: 0.3631 Grad: 59451.0078  LR: 0.00000409  \n",
      "Epoch: [4][20/155] Elapsed 0m 11s (remain 1m 15s) Loss: 0.4107 Grad: 54040.7891  LR: 0.00000365  \n",
      "Epoch: [4][40/155] Elapsed 0m 23s (remain 1m 4s) Loss: 0.4103 Grad: 52038.3281  LR: 0.00000322  \n",
      "Epoch: [4][60/155] Elapsed 0m 34s (remain 0m 52s) Loss: 0.4100 Grad: 57789.5547  LR: 0.00000281  \n",
      "Epoch: [4][80/155] Elapsed 0m 45s (remain 0m 41s) Loss: 0.4079 Grad: 66509.6562  LR: 0.00000242  \n",
      "Epoch: [4][100/155] Elapsed 0m 56s (remain 0m 30s) Loss: 0.4059 Grad: 87526.3906  LR: 0.00000204  \n",
      "Epoch: [4][120/155] Elapsed 1m 7s (remain 0m 19s) Loss: 0.4059 Grad: 65050.7070  LR: 0.00000169  \n",
      "Epoch: [4][140/155] Elapsed 1m 19s (remain 0m 7s) Loss: 0.4042 Grad: 45800.6992  LR: 0.00000137  \n",
      "Epoch: [4][154/155] Elapsed 1m 26s (remain 0m 0s) Loss: 0.4041 Grad: 58920.8164  LR: 0.00000116  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc8fc0b820e1432493af7cedda3965f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/78 [00:00<?, ?valid_batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/78] Elapsed 0m 0s (remain 0m 16s) Loss: 0.4471 \n",
      "EVAL: [20/78] Elapsed 0m 4s (remain 0m 11s) Loss: 0.4501 \n",
      "EVAL: [40/78] Elapsed 0m 8s (remain 0m 7s) Loss: 0.4575 \n",
      "EVAL: [60/78] Elapsed 0m 12s (remain 0m 3s) Loss: 0.4076 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.4041  avg_val_loss: 0.3685  time: 103s\n",
      "Epoch 4 - Score: 0.9971\n",
      "Epoch 4 - Save Best Score: 0.9971 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [77/78] Elapsed 0m 15s (remain 0m 0s) Loss: 0.3685 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5321cfacf60641a8a371aa8b6ae4feb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/155 [00:00<?, ?train_batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][0/155] Elapsed 0m 0s (remain 1m 42s) Loss: 0.3957 Grad: 50737.3203  LR: 0.00000114  \n",
      "Epoch: [5][20/155] Elapsed 0m 11s (remain 1m 15s) Loss: 0.4082 Grad: 84983.5391  LR: 0.00000087  \n",
      "Epoch: [5][40/155] Elapsed 0m 23s (remain 1m 4s) Loss: 0.4036 Grad: 58541.2148  LR: 0.00000064  \n",
      "Epoch: [5][60/155] Elapsed 0m 34s (remain 0m 52s) Loss: 0.4023 Grad: 43240.8203  LR: 0.00000044  \n",
      "Epoch: [5][80/155] Elapsed 0m 45s (remain 0m 41s) Loss: 0.4055 Grad: 48067.9219  LR: 0.00000027  \n",
      "Epoch: [5][100/155] Elapsed 0m 56s (remain 0m 30s) Loss: 0.4069 Grad: 44936.4297  LR: 0.00000015  \n",
      "Epoch: [5][120/155] Elapsed 1m 7s (remain 0m 19s) Loss: 0.4040 Grad: 45317.4922  LR: 0.00000006  \n",
      "Epoch: [5][140/155] Elapsed 1m 19s (remain 0m 7s) Loss: 0.4047 Grad: 47709.1445  LR: 0.00000001  \n",
      "Epoch: [5][154/155] Elapsed 1m 27s (remain 0m 0s) Loss: 0.4042 Grad: 49101.6367  LR: 0.00000000  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09de930e220540d09bbcfe9f5c5e23f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/78 [00:00<?, ?valid_batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/78] Elapsed 0m 0s (remain 0m 16s) Loss: 0.4488 \n",
      "EVAL: [20/78] Elapsed 0m 4s (remain 0m 11s) Loss: 0.4524 \n",
      "EVAL: [40/78] Elapsed 0m 8s (remain 0m 7s) Loss: 0.4599 \n",
      "EVAL: [60/78] Elapsed 0m 12s (remain 0m 3s) Loss: 0.4119 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.4042  avg_val_loss: 0.3744  time: 103s\n",
      "Epoch 5 - Score: 0.9970\n",
      "========== Fold: 0 result ==========\n",
      "Score: 0.9971\n",
      "========== CV ==========\n",
      "Score: 0.9971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [77/78] Elapsed 0m 15s (remain 0m 0s) Loss: 0.3744 \n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    def get_result(oof_df):\n",
    "        labels = oof_df[\"generated\"].values\n",
    "        preds = oof_df[\"preds\"].values\n",
    "        score = get_score(labels, preds)\n",
    "        LOGGER.info(f'Score: {score:<.4f}')\n",
    "    \n",
    "    if config.TRAIN:\n",
    "        oof_df = pd.DataFrame()\n",
    "        for fold in range(config.FOLDS):\n",
    "            if fold == 0:\n",
    "                _oof_df = train_loop(train_df, fold)\n",
    "                oof_df = pd.concat([oof_df, _oof_df])\n",
    "                LOGGER.info(f\"========== Fold: {fold} result ==========\")\n",
    "                get_result(_oof_df)\n",
    "        oof_df = oof_df.reset_index(drop=True)\n",
    "        LOGGER.info(f\"========== CV ==========\")\n",
    "        get_result(oof_df)\n",
    "        oof_df.to_csv(paths.OUTPUT_DIR + '/oof_df.csv', index=False)\n",
    "    if config.WANDB:\n",
    "        wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "      <th>fold</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0059830c</td>\n",
       "      <td>Cars. Cars have been around since they became ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.362839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>005db917</td>\n",
       "      <td>Transportation is a large necessity in most co...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.351552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>008f63e3</td>\n",
       "      <td>\"America's love affair with it's vehicles seem...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.350474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00940276</td>\n",
       "      <td>How often do you ride in a car? Do you drive a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.360876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00c39458</td>\n",
       "      <td>Cars are a wonderful thing. They are perhaps o...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>82DE4E49CC52</td>\n",
       "      <td>Thomas Jefferson wrote determine never to be i...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.850914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>82F7210163B5</td>\n",
       "      <td>When learning at school with other students wh...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.849496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>82F7D233871E</td>\n",
       "      <td>Some schools have a program that pairs older s...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.836759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242</th>\n",
       "      <td>82F9FDBD6F98</td>\n",
       "      <td>My argument about the 10pm curfew for teenager...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.830764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1243</th>\n",
       "      <td>830CCF8E0B23</td>\n",
       "      <td>Elective ClassesI believe that classes like ar...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.842058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1244 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id                                               text  generated  fold     preds\n",
       "0         0059830c  Cars. Cars have been around since they became ...          0   0.0  0.362839\n",
       "1         005db917  Transportation is a large necessity in most co...          0   0.0  0.351552\n",
       "2         008f63e3  \"America's love affair with it's vehicles seem...          0   0.0  0.350474\n",
       "3         00940276  How often do you ride in a car? Do you drive a...          0   0.0  0.360876\n",
       "4         00c39458  Cars are a wonderful thing. They are perhaps o...          0   0.0  0.372675\n",
       "...            ...                                                ...        ...   ...       ...\n",
       "1239  82DE4E49CC52  Thomas Jefferson wrote determine never to be i...          1   0.0  0.850914\n",
       "1240  82F7210163B5  When learning at school with other students wh...          1   0.0  0.849496\n",
       "1241  82F7D233871E  Some schools have a program that pairs older s...          1   0.0  0.836759\n",
       "1242  82F9FDBD6F98  My argument about the 10pm curfew for teenager...          1   0.0  0.830764\n",
       "1243  830CCF8E0B23  Elective ClassesI believe that classes like ar...          1   0.0  0.842058\n",
       "\n",
       "[1244 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_df[\"preds\"] = oof_df[\"preds\"].apply(lambda x: sigmoid(x))\n",
    "oof_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b><span style='color:#F1A424'>Confusion Matrix</span></b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Confusion Matrix')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def binarize(x, threshold):\n",
    "    if x > threshold:\n",
    "        x = 1\n",
    "    else:\n",
    "        x = 0\n",
    "    return x\n",
    "\n",
    "# Assuming df is your pandas DataFrame\n",
    "oof_df[\"binary\"] = oof_df[\"preds\"].apply(lambda x: binarize(x, 0.5))\n",
    "true_labels = oof_df[\"generated\"].values\n",
    "predicted_labels = oof_df[\"binary\"].values\n",
    "\n",
    "# Get the unique classes from both true and predicted labels\n",
    "classes = np.unique(np.concatenate((true_labels, predicted_labels)))\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(true_labels, predicted_labels, labels=classes)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=classes, yticklabels=classes)\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.title(\"Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: kaggle/working/output/ (stored 0%)\n",
      "  adding: kaggle/working/output/config.pth (deflated 50%)\n",
      "  adding: kaggle/working/output/bettertextapp_gpt2-large-detector-de-v1_fold_0_best.pth (deflated 26%)\n",
      "  adding: kaggle/working/output/oof_df.csv (deflated 68%)\n",
      "  adding: kaggle/working/output/.DS_Store (deflated 91%)\n",
      "  adding: kaggle/working/output/tokenizer/ (stored 0%)\n",
      "  adding: kaggle/working/output/tokenizer/tokenizer.json (deflated 76%)\n",
      "  adding: kaggle/working/output/tokenizer/special_tokens_map.json (deflated 51%)\n",
      "  adding: kaggle/working/output/tokenizer/added_tokens.json (stored 0%)\n",
      "  adding: kaggle/working/output/tokenizer/tokenizer_config.json (deflated 79%)\n",
      "  adding: kaggle/working/output/tokenizer/.DS_Store (deflated 97%)\n",
      "  adding: kaggle/working/output/tokenizer/sentencepiece.bpe.model (deflated 49%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r output.zip ./kaggle/working/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training End\n"
     ]
    }
   ],
   "source": [
    "print('Training End')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
